{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "60d9bb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in /home/hua/anaconda3/envs/kondo/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: pyaudio in /home/hua/anaconda3/envs/kondo/lib/python3.10/site-packages (0.2.12)\n",
      "Requirement already satisfied: editdistance in /home/hua/anaconda3/envs/kondo/lib/python3.10/site-packages (0.6.0)\n",
      "Requirement already satisfied: gTTS in /home/hua/anaconda3/envs/kondo/lib/python3.10/site-packages (2.2.4)\n",
      "Requirement already satisfied: requests in /home/hua/anaconda3/envs/kondo/lib/python3.10/site-packages (from gTTS) (2.28.1)\n",
      "Requirement already satisfied: six in /home/hua/anaconda3/envs/kondo/lib/python3.10/site-packages (from gTTS) (1.16.0)\n",
      "Requirement already satisfied: click in /home/hua/anaconda3/envs/kondo/lib/python3.10/site-packages (from gTTS) (8.1.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/hua/anaconda3/envs/kondo/lib/python3.10/site-packages (from requests->gTTS) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/hua/anaconda3/envs/kondo/lib/python3.10/site-packages (from requests->gTTS) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/hua/anaconda3/envs/kondo/lib/python3.10/site-packages (from requests->gTTS) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/hua/anaconda3/envs/kondo/lib/python3.10/site-packages (from requests->gTTS) (3.3)\n",
      "Requirement already satisfied: sklearn in /home/hua/anaconda3/envs/kondo/lib/python3.10/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /home/hua/anaconda3/envs/kondo/lib/python3.10/site-packages (from sklearn) (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/hua/anaconda3/envs/kondo/lib/python3.10/site-packages (from scikit-learn->sklearn) (1.23.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/hua/anaconda3/envs/kondo/lib/python3.10/site-packages (from scikit-learn->sklearn) (1.9.2)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /home/hua/anaconda3/envs/kondo/lib/python3.10/site-packages (from scikit-learn->sklearn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/hua/anaconda3/envs/kondo/lib/python3.10/site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: nltk in /home/hua/anaconda3/envs/kondo/lib/python3.10/site-packages (3.7)\n",
      "Requirement already satisfied: click in /home/hua/anaconda3/envs/kondo/lib/python3.10/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: tqdm in /home/hua/anaconda3/envs/kondo/lib/python3.10/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: joblib in /home/hua/anaconda3/envs/kondo/lib/python3.10/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/hua/anaconda3/envs/kondo/lib/python3.10/site-packages (from nltk) (2022.9.13)\n",
      "[sudo] password for hua: \n"
     ]
    }
   ],
   "source": [
    "!pip install SpeechRecognition\n",
    "!pip install pyaudio\n",
    "!pip install editdistance\n",
    "!pip install gTTS\n",
    "!pip install sklearn\n",
    "!pip install nltk\n",
    "# sudo apt install portaudio19-dev python3-pyaudio\n",
    "# sudo apt-get install portaudio19-dev python-pyaudio python3-pyaudio\n",
    "#!sudo apt update && sudo apt install espeak ffmpeg libespeak1 for offline text_to_voice convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1721896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "# initialize Text-to-speech engine\n",
    "engine = pyttsx3.init()\n",
    "# setting new voice rate (faster)\n",
    "engine.setProperty(\"rate\", 150)\n",
    "\n",
    "# convert this text to speech\n",
    "\n",
    "text = \"Hello, Kondo\"\n",
    "\n",
    "engine.say(text)\n",
    "# play the speech\n",
    "engine.runAndWait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9423296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "\n",
    "r = sr.Recognizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9dda49d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib confmisc.c:1281:(snd_func_refer) Unable to find definition 'cards.acp.pcm.front.0:CARD=0'\n",
      "ALSA lib conf.c:4732:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5220:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM front\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib confmisc.c:1281:(snd_func_refer) Unable to find definition 'cards.acp.pcm.surround51.0:CARD=0'\n",
      "ALSA lib conf.c:4732:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5220:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM surround21\n",
      "ALSA lib confmisc.c:1281:(snd_func_refer) Unable to find definition 'cards.acp.pcm.surround51.0:CARD=0'\n",
      "ALSA lib conf.c:4732:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5220:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM surround21\n",
      "ALSA lib confmisc.c:1281:(snd_func_refer) Unable to find definition 'cards.acp.pcm.surround40.0:CARD=0'\n",
      "ALSA lib conf.c:4732:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5220:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM surround40\n",
      "ALSA lib confmisc.c:1281:(snd_func_refer) Unable to find definition 'cards.acp.pcm.surround51.0:CARD=0'\n",
      "ALSA lib conf.c:4732:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5220:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM surround41\n",
      "ALSA lib confmisc.c:1281:(snd_func_refer) Unable to find definition 'cards.acp.pcm.surround51.0:CARD=0'\n",
      "ALSA lib conf.c:4732:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5220:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM surround50\n",
      "ALSA lib confmisc.c:1281:(snd_func_refer) Unable to find definition 'cards.acp.pcm.surround51.0:CARD=0'\n",
      "ALSA lib conf.c:4732:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5220:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM surround51\n",
      "ALSA lib confmisc.c:1281:(snd_func_refer) Unable to find definition 'cards.acp.pcm.surround71.0:CARD=0'\n",
      "ALSA lib conf.c:4732:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5220:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM surround71\n",
      "ALSA lib confmisc.c:1281:(snd_func_refer) Unable to find definition 'cards.acp.pcm.iec958.0:CARD=0,AES0=4,AES1=130,AES2=0,AES3=2'\n",
      "ALSA lib conf.c:4732:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5220:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM iec958\n",
      "ALSA lib confmisc.c:1281:(snd_func_refer) Unable to find definition 'cards.acp.pcm.iec958.0:CARD=0,AES0=4,AES1=130,AES2=0,AES3=2'\n",
      "ALSA lib conf.c:4732:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5220:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM spdif\n",
      "ALSA lib confmisc.c:1281:(snd_func_refer) Unable to find definition 'cards.acp.pcm.iec958.0:CARD=0,AES0=4,AES1=130,AES2=0,AES3=2'\n",
      "ALSA lib conf.c:4732:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5220:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM spdif\n",
      "ALSA lib confmisc.c:1281:(snd_func_refer) Unable to find definition 'cards.acp.pcm.hdmi.0:CARD=0,AES0=4,AES1=130,AES2=0,AES3=2'\n",
      "ALSA lib conf.c:4732:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5220:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM hdmi\n",
      "ALSA lib confmisc.c:1281:(snd_func_refer) Unable to find definition 'cards.acp.pcm.hdmi.0:CARD=0,AES0=4,AES1=130,AES2=0,AES3=2'\n",
      "ALSA lib conf.c:4732:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5220:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM hdmi\n",
      "ALSA lib confmisc.c:1281:(snd_func_refer) Unable to find definition 'cards.acp.pcm.modem.0:CARD=0'\n",
      "ALSA lib conf.c:4732:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5220:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.phoneline:CARD=0,DEV=0\n",
      "ALSA lib confmisc.c:1281:(snd_func_refer) Unable to find definition 'cards.acp.pcm.modem.0:CARD=0'\n",
      "ALSA lib conf.c:4732:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5220:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.phoneline:CARD=0,DEV=0\n",
      "ALSA lib confmisc.c:1281:(snd_func_refer) Unable to find definition 'cards.acp.pcm.modem.0:CARD=0'\n",
      "ALSA lib conf.c:4732:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5220:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM phoneline\n",
      "ALSA lib confmisc.c:1281:(snd_func_refer) Unable to find definition 'cards.acp.pcm.modem.0:CARD=0'\n",
      "ALSA lib conf.c:4732:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5220:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM phoneline\n",
      "ALSA lib pcm_oss.c:377:(_snd_pcm_oss_open) Unknown field port\n",
      "ALSA lib pcm_oss.c:377:(_snd_pcm_oss_open) Unknown field port\n",
      "ALSA lib pcm_usb_stream.c:486:(_snd_pcm_usb_stream_open) Invalid type for card\n",
      "ALSA lib pcm_usb_stream.c:486:(_snd_pcm_usb_stream_open) Invalid type for card\n",
      "ALSA lib pcm_dmix.c:1089:(snd_pcm_dmix_open) unable to open slave\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sesinizi Tanımlıyor…\n",
      "2\n"
     ]
    },
    {
     "ename": "UnknownValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownValueError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/hua/kondo_speach_features/speach_module.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/hua/kondo_speach_features/speach_module.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSesinizi Tanımlıyor…\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/hua/kondo_speach_features/speach_module.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m2\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/hua/kondo_speach_features/speach_module.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m text \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39;49mrecognize_google(data,language\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mru\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/hua/kondo_speach_features/speach_module.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/hua/kondo_speach_features/speach_module.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(text)\n",
      "File \u001b[0;32m~/anaconda3/envs/kondo/lib/python3.10/site-packages/speech_recognition/__init__.py:858\u001b[0m, in \u001b[0;36mRecognizer.recognize_google\u001b[0;34m(self, audio_data, key, language, show_all)\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[39m# return results\u001b[39;00m\n\u001b[1;32m    857\u001b[0m \u001b[39mif\u001b[39;00m show_all: \u001b[39mreturn\u001b[39;00m actual_result\n\u001b[0;32m--> 858\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(actual_result, \u001b[39mdict\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(actual_result\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39malternative\u001b[39m\u001b[39m\"\u001b[39m, [])) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: \u001b[39mraise\u001b[39;00m UnknownValueError()\n\u001b[1;32m    860\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mconfidence\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m actual_result[\u001b[39m\"\u001b[39m\u001b[39malternative\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    861\u001b[0m     \u001b[39m# return alternative with highest confidence score\u001b[39;00m\n\u001b[1;32m    862\u001b[0m     best_hypothesis \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(actual_result[\u001b[39m\"\u001b[39m\u001b[39malternative\u001b[39m\u001b[39m\"\u001b[39m], key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m alternative: alternative[\u001b[39m\"\u001b[39m\u001b[39mconfidence\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[0;31mUnknownValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with sr.Microphone() as source:\n",
    "    r.adjust_for_ambient_noise(source)\n",
    "    data = r.record(source, duration=5)\n",
    "    print(\"Sesinizi Tanımlıyor…\")\n",
    "    print(2)\n",
    "    text = r.recognize_google(data,language='ru')\n",
    "    print(1)\n",
    "    print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16151bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/hua/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/hua/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "import random\n",
    "import string\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "from gtts import gTTS\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "import speech_recognition as sr \n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#for downloading package files can be commented after First run\n",
    "nltk.download('popular', quiet=True)\n",
    "nltk.download('nps_chat',quiet=True)\n",
    "nltk.download('punkt') \n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad14b2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = nltk.corpus.nps_chat.xml_posts()[:10000]\n",
    "# To Recognise input type as QUES. \n",
    "def dialogue_act_features(post):\n",
    "    features = {}\n",
    "    for word in nltk.word_tokenize(post):\n",
    "        features['contains({})'.format(word.lower())] = True\n",
    "    return features\n",
    "featuresets = [(dialogue_act_features(post.text), post.get('class')) for post in posts]\n",
    "size = int(len(featuresets) * 0.1)\n",
    "train_set, test_set = featuresets[size:], featuresets[:size]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3f5e2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keyword Matching\n",
    "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\n",
    "GREETING_RESPONSES = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\n",
    "def greeting(sentence):\n",
    "    \"\"\"If user's input is a greeting, return a greeting response\"\"\"\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bdd5c3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in the input_corpus\n",
    "#with open('intro_join','r', encoding='utf8', errors ='ignore') as fin:\n",
    "#     raw = fin.read().lower()\n",
    "raw = text\n",
    "#TOkenisation\n",
    "sent_tokens = nltk.sent_tokenize(raw)# converts to list of sentences \n",
    "word_tokens = nltk.word_tokenize(raw)# converts to list of words\n",
    "# Preprocessing\n",
    "lemmer = WordNetLemmatizer()\n",
    "def LemTokens(tokens): \n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b507ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#colour palet\n",
    "def prRed(skk): print(\"\\033[91m {}\\033[00m\" .format(skk)) \n",
    "def prGreen(skk): print(\"\\033[92m {}\\033[00m\" .format(skk)) \n",
    "def prYellow(skk): print(\"\\033[93m {}\\033[00m\" .format(skk)) \n",
    "def prLightPurple(skk): print(\"\\033[94m {}\\033[00m\" .format(skk)) \n",
    "def prPurple(skk): print(\"\\033[95m {}\\033[00m\" .format(skk)) \n",
    "def prCyan(skk): print(\"\\033[96m {}\\033[00m\" .format(skk)) \n",
    "def prLightGray(skk): print(\"\\033[97m {}\\033[00m\" .format(skk)) \n",
    "def prBlack(skk): print(\"\\033[98m {}\\033[00m\" .format(skk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "67692898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating response and processing \n",
    "def response(user_response):\n",
    "    robo_response=''\n",
    "    sent_tokens.append(user_response)\n",
    "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    idx=vals.argsort()[0][-2]\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    if(req_tfidf==0):\n",
    "        robo_response=robo_response+\"I am sorry! I don't understand you\"\n",
    "        return robo_response\n",
    "    else:\n",
    "        robo_response = robo_response+sent_tokens[idx]\n",
    "        return robo_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "25a618d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m My name is Kondo. I will do what you want. If you want to exit, say Bye\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: 1: mpg123: not found\n"
     ]
    }
   ],
   "source": [
    "#Recording voice input using microphone \n",
    "file = \"file.mp3\"\n",
    "flag=True\n",
    "fst=\"My name is Kondo. I will do what you want. If you want to exit, say Bye\"\n",
    "tts = gTTS(fst, lang=\"en\",tld=\"com\")\n",
    "tts.save(file)\n",
    "os.system(\"mpg123 \" + file )\n",
    "r = sr.Recognizer()\n",
    "prYellow(fst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f041b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yandex-music\n",
      "  Downloading yandex-music-2.0.1.tar.gz (158 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m659.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m677.4 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests[socks] in /home/hua/anaconda3/envs/kondo/lib/python3.10/site-packages (from yandex-music) (2.28.1)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting aiofiles\n",
      "  Downloading aiofiles-22.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/hua/anaconda3/envs/kondo/lib/python3.10/site-packages (from aiohttp->yandex-music) (22.1.0)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/hua/anaconda3/envs/kondo/lib/python3.10/site-packages (from aiohttp->yandex-music) (2.1.1)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (263 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.0/264.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /home/hua/anaconda3/envs/kondo/lib/python3.10/site-packages (from requests[socks]->yandex-music) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/hua/anaconda3/envs/kondo/lib/python3.10/site-packages (from requests[socks]->yandex-music) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/hua/anaconda3/envs/kondo/lib/python3.10/site-packages (from requests[socks]->yandex-music) (3.3)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/hua/anaconda3/envs/kondo/lib/python3.10/site-packages (from requests[socks]->yandex-music) (1.7.1)\n",
      "Building wheels for collected packages: yandex-music\n",
      "  Building wheel for yandex-music (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for yandex-music: filename=yandex_music-2.0.1-py3-none-any.whl size=280220 sha256=4b849e15c836b5282109fe0e036e63a21159674a93fcf10bbb8fc5ae065e6543\n",
      "  Stored in directory: /home/hua/.cache/pip/wheels/1c/f9/07/f0ba69082fae654c12359f7986adddda0aad858ef1f892cfc5\n",
      "Successfully built yandex-music\n",
      "Installing collected packages: multidict, frozenlist, async-timeout, aiofiles, yarl, aiosignal, aiohttp, yandex-music\n",
      "Successfully installed aiofiles-22.1.0 aiohttp-3.8.3 aiosignal-1.2.0 async-timeout-4.0.2 frozenlist-1.3.1 multidict-6.0.2 yandex-music-2.0.1 yarl-1.8.1\n"
     ]
    }
   ],
   "source": [
    "# Yandex music API\n",
    "!pip install yandex-music --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a5a2829",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yandex_music import Client\n",
    "\n",
    "client = Client(\"y0_AgAAAAAqvlDlAAiJcgAAAADSicCfF-W6WmPOSTaafBFgACMr9Eq5wU4\").init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9bcdc42a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44856687"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.tracks(['10994777:1193829', '40133452:5206873', '48966383:6693286', '51385674:7163467'])[0]\n",
    "#client.tracks_download_info(38318)[0].download(filename=\"1.mpg\")\n",
    "client.search(\"Birds\")[\"best\"][\"result\"][\"id\"]#.download(filename=\"1.mpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "617ef732",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from playsound import playsound\n",
    "playsound(\"1.mpg\")\n",
    "\n",
    "#!pip install playsound\n",
    "def play_music_by_id(id):\n",
    "    client.tracks_download_info(38318)[0].download(filename=\"1.mpg\") # add id\n",
    "    playsound(\"1.mpg\")\n",
    "def play_music_by_name(name):\n",
    "    client.tracks_download_info(client.search(name)[\"best\"][\"result\"][\"id\"])[0].download(filename=\"1.mpg\") # add id\n",
    "    import time\n",
    "    time.sleep(3)\n",
    "    playsound(\"1.mpg\")\n",
    "\n",
    "play_music_by_name(\"Closed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0315e9ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60362379"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.search(\"closed\")[\"best\"][\"result\"][\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "16aef513",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/hua/anaconda3/envs/kondo/lib/python3.10/site-packages/playsound.py\", line 261, in <module>\n",
      "    playsound(argv[1])\n",
      "  File \"/home/hua/anaconda3/envs/kondo/lib/python3.10/site-packages/playsound.py\", line 189, in _playsoundNix\n",
      "    bus.poll(Gst.MessageType.EOS, Gst.CLOCK_TIME_NONE)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "nothing  = lambda x:None\n",
    "commands = {\"Play music\":lambda id:play_music_by_name(id), \"Move Head\":nothing , \"Go forward\":nothing, \"Go backward\":nothing, \"Turn right\":nothing, \"Turn left\":nothing}\n",
    "key_words_command = {\"music\":commands[\"Play music\"]}\n",
    "key_words_command[\"music\"](1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b4bdc6fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"music Tokyo Drift\".find(\"music\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "96beff34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m YOU SAID : play claws\u001b[00m\n",
      "Start play music\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/hua/kondo_speach_features/speach_module.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hua/kondo_speach_features/speach_module.ipynb#X16sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mplay\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m user_response):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hua/kondo_speach_features/speach_module.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mStart play music\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/hua/kondo_speach_features/speach_module.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     key_words_command[\u001b[39m\"\u001b[39;49m\u001b[39mmusic\u001b[39;49m\u001b[39m\"\u001b[39;49m](user_response\u001b[39m.\u001b[39;49mfind(\u001b[39m\"\u001b[39;49m\u001b[39mmusic\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39m+\u001b[39;49m \u001b[39mlen\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mmusic\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hua/kondo_speach_features/speach_module.ipynb#X16sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m clas\u001b[39m=\u001b[39mclassifier\u001b[39m.\u001b[39mclassify(dialogue_act_features(user_response))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hua/kondo_speach_features/speach_module.ipynb#X16sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(clas)\n",
      "\u001b[1;32m/home/hua/kondo_speach_features/speach_module.ipynb Cell 19\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(id)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/hua/kondo_speach_features/speach_module.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m nothing  \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x:\u001b[39mNone\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/hua/kondo_speach_features/speach_module.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m commands \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mPlay music\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39mlambda\u001b[39;00m \u001b[39mid\u001b[39m:play_music_by_id(\u001b[39mid\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39mMove Head\u001b[39m\u001b[39m\"\u001b[39m:nothing , \u001b[39m\"\u001b[39m\u001b[39mGo forward\u001b[39m\u001b[39m\"\u001b[39m:nothing, \u001b[39m\"\u001b[39m\u001b[39mGo backward\u001b[39m\u001b[39m\"\u001b[39m:nothing, \u001b[39m\"\u001b[39m\u001b[39mTurn right\u001b[39m\u001b[39m\"\u001b[39m:nothing, \u001b[39m\"\u001b[39m\u001b[39mTurn left\u001b[39m\u001b[39m\"\u001b[39m:nothing}\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/hua/kondo_speach_features/speach_module.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m key_words_command \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmusic\u001b[39m\u001b[39m\"\u001b[39m:commands[\u001b[39m\"\u001b[39m\u001b[39mPlay music\u001b[39m\u001b[39m\"\u001b[39m]}\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/hua/kondo_speach_features/speach_module.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m key_words_command[\u001b[39m\"\u001b[39m\u001b[39mmusic\u001b[39m\u001b[39m\"\u001b[39m](\u001b[39m1\u001b[39m)\n",
      "\u001b[1;32m/home/hua/kondo_speach_features/speach_module.ipynb Cell 19\u001b[0m in \u001b[0;36mplay_music_by_id\u001b[0;34m(id)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/hua/kondo_speach_features/speach_module.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplay_music_by_id\u001b[39m(\u001b[39mid\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/hua/kondo_speach_features/speach_module.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     client\u001b[39m.\u001b[39mtracks_download_info(\u001b[39m38318\u001b[39m)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdownload(filename\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m1.mpg\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m# add id\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/hua/kondo_speach_features/speach_module.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     playsound(\u001b[39m\"\u001b[39;49m\u001b[39m1.mpg\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/kondo/lib/python3.10/site-packages/playsound.py:254\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(sound, block)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m             logger\u001b[39m.\u001b[39mwarning(\u001b[39m\"\u001b[39m\u001b[39mplaysound is relying on another python subprocess. Please use `pip install pygobject` if you want playsound to run more efficiently.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 254\u001b[0m             playsound \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m sound, block \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m: _playsoundAnotherPython(\u001b[39m'\u001b[39;49m\u001b[39m/usr/bin/python3\u001b[39;49m\u001b[39m'\u001b[39;49m, sound, block, macOS \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    256\u001b[0m \u001b[39mdel\u001b[39;00m system\n\u001b[1;32m    258\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    259\u001b[0m     \u001b[39m# block is always True if you choose to run this from the command line.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/kondo/lib/python3.10/site-packages/playsound.py:229\u001b[0m, in \u001b[0;36m_playsoundAnotherPython\u001b[0;34m(otherPython, sound, block, macOS)\u001b[0m\n\u001b[1;32m    227\u001b[0m t\u001b[39m.\u001b[39mstart()\n\u001b[1;32m    228\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[0;32m--> 229\u001b[0m     t\u001b[39m.\u001b[39;49mjoin()\n",
      "File \u001b[0;32m~/anaconda3/envs/kondo/lib/python3.10/site-packages/playsound.py:216\u001b[0m, in \u001b[0;36m_playsoundAnotherPython.<locals>.PropogatingThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mjoin\u001b[39m(\u001b[39mself\u001b[39m, timeout \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 216\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mjoin(timeout)\n\u001b[1;32m    217\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexc:\n\u001b[1;32m    218\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexc\n",
      "File \u001b[0;32m~/anaconda3/envs/kondo/lib/python3.10/threading.py:1096\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot join current thread\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1095\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1096\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait_for_tstate_lock()\n\u001b[1;32m   1097\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[39m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m     \u001b[39m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(timeout, \u001b[39m0\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/kondo/lib/python3.10/threading.py:1116\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1116\u001b[0m     \u001b[39mif\u001b[39;00m lock\u001b[39m.\u001b[39;49macquire(block, timeout):\n\u001b[1;32m   1117\u001b[0m         lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m   1118\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while(flag==True):\n",
    "    with sr.Microphone() as source:\n",
    "        audio= r.listen(source, phrase_time_limit=3)\n",
    "    try:\n",
    "        user_response = format(r.recognize_google(audio))\n",
    "        print(\"\\033[91m {}\\033[00m\" .format(\"YOU SAID : \"+user_response))\n",
    "    except sr.UnknownValueError:\n",
    "        prYellow(\"Oops! Didn't catch that\")\n",
    "    \n",
    "    #user_response = input()\n",
    "    #user_response=user_response.lower()\n",
    "    if (\"play\" in user_response):\n",
    "        print(\"Start play music\")\n",
    "        key_words_command[\"music\"](user_response.find(\"music\") + len(\"music\"))\n",
    "    clas=classifier.classify(dialogue_act_features(user_response))\n",
    "    print(clas)\n",
    "    if(clas!='Bye'):\n",
    "        if(clas=='Emotion'):\n",
    "            flag=False\n",
    "            text = \"Kondo: You are welcome..\"\n",
    "            prYellow(text)\n",
    "            engine.say(text)\n",
    "            engine.runAndWait()\n",
    "                \n",
    "        else:\n",
    "            if(greeting(user_response)!=None):\n",
    "\n",
    "                text = greeting(user_response) \n",
    "                \n",
    "                engine.say(text)\n",
    "                engine.runAndWait()\n",
    "                print(\"\\033[93m {}\\033[00m\" .format(\"Kondo: \"+ text))\n",
    "            else:\n",
    "                print(\"\\033[93m {}\\033[00m\" .format(\"Kondo: \",end=\"\"))\n",
    "                res=(response(user_response))\n",
    "                engine.say(res)\n",
    "                engine.runAndWait()\n",
    "                prYellow(res)\n",
    "                sent_tokens.remove(user_response)\n",
    "                tts = gTTS(res, 'en')\n",
    "                tts.save(file)\n",
    "                os.system(\"mpg123 \" + file)\n",
    "    else:\n",
    "        flag=False\n",
    "        text = \"Kondo: Bye! take care..\"\n",
    "        prYellow(text)\n",
    "        engine.say(text)\n",
    "        # play the speech\n",
    "        engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f983285c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc5662f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3815944",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('kondo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "3aa7e6e0394914080f6539c0e6bebad171a620d9008ced8195097ff99ce151b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
